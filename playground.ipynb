{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyomo Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipopt 3.14.16: \n",
      "==> Warning: Treating 0 binary and 10 integer variables as continuous.\n",
      "\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.14.16, running with linear solver MUMPS 5.6.2.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:       14\n",
      "Number of nonzeros in Lagrangian Hessian.............:       55\n",
      "\n",
      "Total number of variables............................:       10\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:       10\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        5\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        5\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 -2.2959893e-01 0.00e+00 7.01e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1 -5.8219350e-01 0.00e+00 8.16e+00  -1.0 5.75e-02   2.0 1.00e+00 5.91e-01f  1\n",
      "   2 -1.5003218e+00 0.00e+00 8.12e+00  -1.0 1.19e-01    -  3.40e-01 1.00e+00f  1\n",
      "   3 -1.8627760e+00 0.00e+00 6.22e+00  -1.0 2.29e-02   2.4 1.00e+00 1.00e+00f  1\n",
      "   4 -2.0551987e+00 0.00e+00 6.40e+00  -1.0 8.95e-03   2.9 1.00e+00 1.00e+00f  1\n",
      "   5 -3.6255246e+00 0.00e+00 1.99e+01  -1.0 3.58e-02   2.4 1.00e+00 1.00e+00f  1\n",
      "   6 -3.2395054e+00 0.00e+00 8.32e+00  -1.0 1.32e-02   2.8 1.00e+00 1.00e+00f  1\n",
      "   7 -5.8674013e+00 0.00e+00 3.38e+01  -1.0 5.34e-02   2.3 1.00e+00 7.23e-01f  1\n",
      "   8 -7.3561853e+00 0.00e+00 9.43e+00  -1.0 1.27e-01   1.8 1.00e+00 1.00e+00f  1\n",
      "   9 -1.2968646e+01 0.00e+00 1.02e+02  -1.0 6.03e-01   1.4 7.29e-01 3.11e-01f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10 -2.2284457e+01 0.00e+00 5.51e+02  -1.0 1.48e+00   0.9 1.00e+00 2.71e-01f  1\n",
      "  11 -2.2742877e+01 0.00e+00 1.38e+02  -1.0 3.03e-01    -  1.00e+00 6.81e-02f  1\n",
      "  12 -2.2300948e+01 0.00e+00 4.73e-01  -1.0 1.39e-02    -  1.00e+00 1.00e+00f  1\n",
      "  13 -2.3061125e+01 0.00e+00 1.52e+00  -1.7 1.22e-02    -  1.00e+00 1.00e+00f  1\n",
      "  14 -2.3016664e+01 0.00e+00 5.68e-03  -1.7 6.39e-04    -  1.00e+00 1.00e+00f  1\n",
      "  15 -2.3217903e+01 0.00e+00 2.43e-02  -3.8 4.06e-03    -  1.00e+00 9.90e-01f  1\n",
      "  16 -2.3216649e+01 0.00e+00 5.08e-06  -3.8 2.29e-05    -  1.00e+00 1.00e+00f  1\n",
      "  17 -2.3218135e+01 0.00e+00 6.05e-06  -5.7 2.95e-05    -  1.00e+00 1.00e+00f  1\n",
      "  18 -2.3218153e+01 0.00e+00 9.12e-10  -8.6 3.62e-07    -  1.00e+00 1.00e+00f  1\n",
      "\n",
      "Number of Iterations....: 18\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  -2.3218153187634897e+01   -2.3218153187634897e+01\n",
      "Dual infeasibility......:   9.1246247966751543e-10    9.1246247966751543e-10\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Variable bound violation:   9.9952978373636260e-09    9.9952978373636260e-09\n",
      "Complementarity.........:   2.5060275538792069e-09    2.5060275538792069e-09\n",
      "Overall NLP error.......:   2.0274445598324618e-09    2.5060275538792069e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 19\n",
      "Number of objective gradient evaluations             = 19\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 19\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 19\n",
      "Number of Lagrangian Hessian evaluations             = 18\n",
      "Total seconds in IPOPT                               = 0.009\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "\bOptimal link schedule: [1.0000000098921296, -9.989513994883995e-09, -9.994430147011644e-09, -9.987692034111553e-09, -9.988201439008457e-09, -9.995062803396107e-09, -9.995127923272992e-09, -9.513430170378704e-09, -9.995297837363626e-09, -9.993820404329955e-09]\n",
      "Maximum throughput: 23.218153187634897\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyomo.environ import (\n",
    "    ConcreteModel, Var, Objective, ConstraintList, SolverFactory, NonNegativeReals, Binary, maximize\n",
    ")\n",
    "\n",
    "# Step 1: Define problem parameters\n",
    "V_H = 10  # Number of nodes (links)\n",
    "E_H = 5   # Number of hyperedges\n",
    "\n",
    "# Signal strengths, noise power, and interference matrix\n",
    "N = np.random.rand(V_H)  # Noise power\n",
    "I = np.random.rand(V_H, V_H)  # Interference matrix (I_ij)\n",
    "\n",
    "# Hyperedges (list of node indices per hyperedge)\n",
    "hyperedges = [\n",
    "    [0, 1, 2],\n",
    "    [2, 3, 4],\n",
    "    [4, 5, 6],\n",
    "    [6, 7, 8],\n",
    "    [8, 9]\n",
    "]\n",
    "\n",
    "# Thresholds for hyperedges\n",
    "theta = np.random.rand(E_H)\n",
    "\n",
    "# Step 2: Create Pyomo model\n",
    "model = ConcreteModel()\n",
    "\n",
    "# Step 3: Define binary decision variables for each link (b_i)\n",
    "model.b = Var(range(V_H), domain=Binary)  # b[i] = 1 if link i is active, 0 otherwise\n",
    "\n",
    "# Step 4: Define the objective function (maximize throughput)\n",
    "def throughput(model):\n",
    "    total_throughput = 0\n",
    "    for i in range(V_H):\n",
    "        interference = sum(model.b[j] * I[i, j] for j in range(V_H) if j != i)  # Interference from other active links\n",
    "        denominator = N[i] + interference  # Noise + interference\n",
    "        total_throughput += (I[i,i] * model.b[i]) / denominator  # Contribution of link i to throughput\n",
    "    return total_throughput\n",
    "\n",
    "model.obj = Objective(rule=throughput, sense=maximize)\n",
    "\n",
    "# Step 5: Add constraints for hyperedges (each hyperedge has a threshold)\n",
    "model.constraints = ConstraintList()\n",
    "\n",
    "for e_idx, hyperedge in enumerate(hyperedges):\n",
    "    model.constraints.add(\n",
    "        sum(model.b[i] for i in hyperedge) <= len(hyperedge)-1\n",
    "    )\n",
    "\n",
    "# Step 6: Solve the model\n",
    "solver = SolverFactory('ipopt')  # Use Ipopt for nonlinear problems\n",
    "result = solver.solve(model, tee=True)\n",
    "\n",
    "# Step 7: Extract the results\n",
    "optimal_decisions = [model.b[i].value for i in range(V_H)]\n",
    "\n",
    "# Output the optimal link schedule\n",
    "print(\"Optimal link schedule:\", optimal_decisions)\n",
    "print(\"Maximum throughput:\", model.obj())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exhaustive Search Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exhaustive search\n",
    "def exh_solver(V_H, E_H, N, I, hyperedges):\n",
    "    best_throughput = 0\n",
    "    best_schedule = None\n",
    "\n",
    "    for i in range(2**V_H):\n",
    "        schedule = [int(x) for x in bin(i)[2:].zfill(V_H)]\n",
    "        throughput = 0\n",
    "\n",
    "        # check if the schedule satisfies the hyperedge constraints\n",
    "        valid_schedule = True\n",
    "        for hyperedge in hyperedges:\n",
    "            if sum(schedule[j] for j in hyperedge) == len(hyperedge):\n",
    "                valid_schedule = False\n",
    "                break\n",
    "        \n",
    "        if not valid_schedule:\n",
    "            continue\n",
    "\n",
    "        # calculate throughput\n",
    "        for i in range(V_H):\n",
    "            interference = sum(schedule[j] * I[i, j] for j in range(V_H) if j != i)\n",
    "            denominator = N[i] + interference\n",
    "            throughput += (I[i,i] * schedule[i]) / denominator\n",
    "        \n",
    "        if throughput > best_throughput:\n",
    "            best_throughput = throughput\n",
    "            best_schedule = schedule\n",
    "\n",
    "    return best_throughput, best_schedule\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exhaustive search results:\n",
      "Optimal link schedule: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Maximum throughput: 99.63409923285451\n"
     ]
    }
   ],
   "source": [
    "best_throughput, best_schedule = exh_solver(V_H, E_H, V_H*[0.01], I, hyperedges)\n",
    "\n",
    "print(\"Exhaustive search results:\")\n",
    "print(\"Optimal link schedule:\", best_schedule)\n",
    "print(\"Maximum throughput:\", best_throughput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format of Data Should be as follows\n",
    "Dictionary Keys: \"$n$\": Number of hypernodes ($|\\mathcal{V}_H|$), \"$E$\": dictionray of hyperedges, \"$I \\in R^{n\\times n}$\": Interference and Power matrix, \"$H \\in \\{0,1\\}^{n\\times m}$: Incident matrix ($m$ is the size of hyperedges) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def hypergraph_generation(V_H, I, hyperedges):\n",
    "    hypergraph = {}\n",
    "\n",
    "    hypergraph[\"n\"] = V_H\n",
    "    hypergraph[\"E\"] = {}\n",
    "\n",
    "    for e_idx, hyperedge in enumerate(hyperedges):\n",
    "        hypergraph[\"E\"][e_idx] = hyperedge\n",
    "\n",
    "\n",
    "    hypergraph[\"I\"] = I\n",
    "\n",
    "    # incident matrix H\n",
    "    H = np.zeros((V_H, len(hyperedges)))\n",
    "    for e_idx, hyperedge in enumerate(hyperedges):\n",
    "        for node in hyperedge:\n",
    "            H[node, e_idx] = 1\n",
    "\n",
    "    hypergraph[\"H\"] = torch.FloatTensor(H)\n",
    "\n",
    "    \n",
    "    return hypergraph\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = hypergraph_generation(V_H, I, hyperedges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/rezaramezanpour/Documents/link_scheduling_hypergraph/model.py'>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, model, networks, utils\n",
    "importlib.reload(networks)\n",
    "importlib.reload(utils)\n",
    "\n",
    "importlib.reload(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**HyperGCN**</span> is defined in <span style=\"color:cyan\">**networks**</span> file, but it's core layer <span style=\"color:red\">*HyperGraphConvolution*</span> is defined in <span style=\"color:cyan\">**utils**</span>.<br /> If you want change the entire model you can put your model in <span style=\"color:cyan\">**networks**</span> file.<br />\n",
    "The training process is defined in the <span style=\"color:cyan\">**model**</span> file, so if you defined a new model and want to use it in training process, please change that file.<br /> Also the <span style=\"color:red\">**Gumbel+LinSatNet**</span> is defined in <span style=\"color:cyan\">**utils**</span> but it is used in training process. Our custom loss function (negative of our objecive) is defined in <span style=\"color:cyan\">**model**</span>, i double checked it with random inputs, so it should be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "HyperGCN = model.initialise(hyp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HyperGCN = model.train(HyperGCN, hyp, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
